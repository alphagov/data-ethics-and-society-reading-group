# Questions for discussion 

## Related to  [Ababa Bihrane 's paper on Algorithmic injustice: a relational ethics approach](https://www.sciencedirect.com/science/article/pii/S2666389921000155) 
1.	How can we leverage data practices in order to gain an in-depth understanding of certain problems as situated in structural inequalities and oppression (e.g. Institutional racism as defined by MacPherson Report)?”
2.	How might a data worker engage vulnerable communities in ways that surface harms, when it is often the case that algorithmic harms may be secondary effects, invisible to designers and communities alike, and what questions might be asked to help anticipate these harms?”

## Related to [Launch of the Centre for Applied Data Ethics](https://uksa.statisticsauthority.gov.uk/publication/centre-for-applied-data-ethics-strategy-enabling-ethically-appropriate-research-and-statistics-for-the-public-good/) 
4.	What are the key challenges for data scientists in considering bias in their work?
5.	Do we know enough about bias and how to prevent it in practice? Or are we still missing things?

## Related to [OSR review of approach to developing statistical models designed for awarding 2020 exam results](https://osr.statisticsauthority.gov.uk/our-regulatory-work/osr-review-of-approach-to-developing-statistical-models-designed-for-awarding-2020-exam-results/)
6.	What could this mean for the models that you build or work with? 
7.	What historical patterns or assumptions could lead to the perception of bias?
8.	How do you/ will you communicate those patterns and assumptions to users of the model so that they understand the impact on results?
