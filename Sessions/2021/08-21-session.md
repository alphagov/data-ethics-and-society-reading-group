# Data Science: Ethics & Society Reading Group 24-08-21 [12:30 - 13:30 GMT](https://www.timeanddate.com/worldclock/fixedtime.html?msg=Data+Science%3A+Ethics+%26+Society+Reading+Group+24-08-2&iso=20210824T1230&p1=136&ah=1)

## Meeting info

### Description

You're welcome to join us for our next Data Science: Ethics & Society Reading Group on Tuesday the 24th August 2021 at [12:30 - 13:30 GMT](https://www.timeanddate.com/worldclock/fixedtime.html?msg=Data+Science%3A+Ethics+%26+Society+Reading+Group+24-08-2&iso=20210824T1230&p1=136&ah=1).

Following our successful event looking at the first three chapters (Earth, Labor and Data), this time we're going to discuss the **final chapters** (Classification, Affect, State & Power) of [Atlas of AI](https://yalebooks.yale.edu/book/9780300209570/atlas-ai) by Kate Crawford.

Atlas of AI presents AI as a technology of extraction: from the minerals drawn from the earth, to the labour pulled from low-wage information workers, to the data taken from every action and expression.

This book can be purchased in the UK from [Blackwell's](https://blackwells.co.uk/bookshop/product/Atlas-of-AI-by-Kate-Crawford-author/9780300209570), [AbeBooks](https://www.abebooks.co.uk/9780300209570/Atlas-Power-Politics-Planetary-Costs-0300209576/plp), [Amazon](https://www.amazon.co.uk/Atlas-AI-Kate-Crawford/dp/0300209576/ref=sr_1_1) (kindle or hardcover), or an independent retailer.

#### **You are very welcome to attend if you haven't read any of the book. You are also welcome if you didn't attend the first event!**. 

We have put together some material related to some of the concepts in the book below.

- [Kate Crawford on “Atlas of AI: Power, Politics, and the Planetary Costs of Artificial Intelligence”](https://www.youtube.com/watch?v=KcefG-0InLE), *Kate Crawford*, (video, 48 mins).
Crawford discusses the book in this sub one-hour video using content from the book itself. If you don't have time to read the book, or read/watch/listen to the below, **please watch this video**.

- [Excavating AI](https://excavating.ai/), *Kate Crawford & Trevor Paglen*
Contains a lot of similar material to the part of the book that interrogates the widespread use of ImageNet.

- [Artificial Intelligence is Misreading Human Emotion](https://www.theatlantic.com/technology/archive/2021/04/artificial-intelligence-misreading-human-emotion/618696/), *Kate Crawford, The Atlantic*. 
This article is adapted from the book's 'Affect' chapter.

- Placeholder for State material

- Placeholder for Power material

Thank you to Harriet for suggesting this week's content, and to all those who suggested content, which we we look forward to sharing at future events.

### Discussion points

There will be time to talk about whatever we like, relating to the paper, but here are some specific questions to think about while you're reading.

- Add discussion points

---

<!--

## Meeting notes

### Who came
Number of people:

### What did we think?
Notes here!
Shall we email the author? If so, who'll send the email?

-->
